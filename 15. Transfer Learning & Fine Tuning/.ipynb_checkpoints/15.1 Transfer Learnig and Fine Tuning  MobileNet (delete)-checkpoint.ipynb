{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learnig and Fine Tuning \n",
    "\n",
    "### Loading the VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-31ea18ee6331>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMobileNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# MobileNet was designed to work on 224 x 224 pixel input images sizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimg_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.applications import MobileNet\n",
    "\n",
    "# MobileNet was designed to work on 224 x 224 pixel input images sizes\n",
    "img_rows = 224\n",
    "img_cols = 224 \n",
    "\n",
    "#Loads the MobileNet model \n",
    "MobileNet = MobileNet(weights = 'imagenet', \n",
    "                 include_top = True, \n",
    "                 input_shape = (img_rows, img_cols, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inpsecting each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer False\n",
      "1 ZeroPadding2D True\n",
      "2 Conv2D True\n",
      "3 BatchNormalization True\n",
      "4 ReLU True\n",
      "5 DepthwiseConv2D True\n",
      "6 BatchNormalization True\n",
      "7 ReLU True\n",
      "8 Conv2D True\n",
      "9 BatchNormalization True\n",
      "10 ReLU True\n",
      "11 ZeroPadding2D True\n",
      "12 DepthwiseConv2D True\n",
      "13 BatchNormalization True\n",
      "14 ReLU True\n",
      "15 Conv2D True\n",
      "16 BatchNormalization True\n",
      "17 ReLU True\n",
      "18 DepthwiseConv2D True\n",
      "19 BatchNormalization True\n",
      "20 ReLU True\n",
      "21 Conv2D True\n",
      "22 BatchNormalization True\n",
      "23 ReLU True\n",
      "24 ZeroPadding2D True\n",
      "25 DepthwiseConv2D True\n",
      "26 BatchNormalization True\n",
      "27 ReLU True\n",
      "28 Conv2D True\n",
      "29 BatchNormalization True\n",
      "30 ReLU True\n",
      "31 DepthwiseConv2D True\n",
      "32 BatchNormalization True\n",
      "33 ReLU True\n",
      "34 Conv2D True\n",
      "35 BatchNormalization True\n",
      "36 ReLU True\n",
      "37 ZeroPadding2D True\n",
      "38 DepthwiseConv2D True\n",
      "39 BatchNormalization True\n",
      "40 ReLU True\n",
      "41 Conv2D True\n",
      "42 BatchNormalization True\n",
      "43 ReLU True\n",
      "44 DepthwiseConv2D True\n",
      "45 BatchNormalization True\n",
      "46 ReLU True\n",
      "47 Conv2D True\n",
      "48 BatchNormalization True\n",
      "49 ReLU True\n",
      "50 DepthwiseConv2D True\n",
      "51 BatchNormalization True\n",
      "52 ReLU True\n",
      "53 Conv2D True\n",
      "54 BatchNormalization True\n",
      "55 ReLU True\n",
      "56 DepthwiseConv2D True\n",
      "57 BatchNormalization True\n",
      "58 ReLU True\n",
      "59 Conv2D True\n",
      "60 BatchNormalization True\n",
      "61 ReLU True\n",
      "62 DepthwiseConv2D True\n",
      "63 BatchNormalization True\n",
      "64 ReLU True\n",
      "65 Conv2D True\n",
      "66 BatchNormalization True\n",
      "67 ReLU True\n",
      "68 DepthwiseConv2D True\n",
      "69 BatchNormalization True\n",
      "70 ReLU True\n",
      "71 Conv2D True\n",
      "72 BatchNormalization True\n",
      "73 ReLU True\n",
      "74 ZeroPadding2D True\n",
      "75 DepthwiseConv2D True\n",
      "76 BatchNormalization True\n",
      "77 ReLU True\n",
      "78 Conv2D True\n",
      "79 BatchNormalization True\n",
      "80 ReLU True\n",
      "81 DepthwiseConv2D True\n",
      "82 BatchNormalization True\n",
      "83 ReLU True\n",
      "84 Conv2D True\n",
      "85 BatchNormalization True\n",
      "86 ReLU True\n",
      "87 GlobalAveragePooling2D True\n",
      "88 Reshape True\n",
      "89 Dropout True\n",
      "90 Conv2D True\n",
      "91 Activation True\n",
      "92 Reshape True\n"
     ]
    }
   ],
   "source": [
    "# Let's print our layers \n",
    "for (i,layer) in enumerate(MobileNet.layers):\n",
    "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's freeze all layers except the top 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer False\n",
      "1 ZeroPadding2D False\n",
      "2 Conv2D False\n",
      "3 BatchNormalization False\n",
      "4 ReLU False\n",
      "5 DepthwiseConv2D False\n",
      "6 BatchNormalization False\n",
      "7 ReLU False\n",
      "8 Conv2D False\n",
      "9 BatchNormalization False\n",
      "10 ReLU False\n",
      "11 ZeroPadding2D False\n",
      "12 DepthwiseConv2D False\n",
      "13 BatchNormalization False\n",
      "14 ReLU False\n",
      "15 Conv2D False\n",
      "16 BatchNormalization False\n",
      "17 ReLU False\n",
      "18 DepthwiseConv2D False\n",
      "19 BatchNormalization False\n",
      "20 ReLU False\n",
      "21 Conv2D False\n",
      "22 BatchNormalization False\n",
      "23 ReLU False\n",
      "24 ZeroPadding2D False\n",
      "25 DepthwiseConv2D False\n",
      "26 BatchNormalization False\n",
      "27 ReLU False\n",
      "28 Conv2D False\n",
      "29 BatchNormalization False\n",
      "30 ReLU False\n",
      "31 DepthwiseConv2D False\n",
      "32 BatchNormalization False\n",
      "33 ReLU False\n",
      "34 Conv2D False\n",
      "35 BatchNormalization False\n",
      "36 ReLU False\n",
      "37 ZeroPadding2D False\n",
      "38 DepthwiseConv2D False\n",
      "39 BatchNormalization False\n",
      "40 ReLU False\n",
      "41 Conv2D False\n",
      "42 BatchNormalization False\n",
      "43 ReLU False\n",
      "44 DepthwiseConv2D False\n",
      "45 BatchNormalization False\n",
      "46 ReLU False\n",
      "47 Conv2D False\n",
      "48 BatchNormalization False\n",
      "49 ReLU False\n",
      "50 DepthwiseConv2D False\n",
      "51 BatchNormalization False\n",
      "52 ReLU False\n",
      "53 Conv2D False\n",
      "54 BatchNormalization False\n",
      "55 ReLU False\n",
      "56 DepthwiseConv2D False\n",
      "57 BatchNormalization False\n",
      "58 ReLU False\n",
      "59 Conv2D False\n",
      "60 BatchNormalization False\n",
      "61 ReLU False\n",
      "62 DepthwiseConv2D False\n",
      "63 BatchNormalization False\n",
      "64 ReLU False\n",
      "65 Conv2D False\n",
      "66 BatchNormalization False\n",
      "67 ReLU False\n",
      "68 DepthwiseConv2D False\n",
      "69 BatchNormalization False\n",
      "70 ReLU False\n",
      "71 Conv2D False\n",
      "72 BatchNormalization False\n",
      "73 ReLU False\n",
      "74 ZeroPadding2D False\n",
      "75 DepthwiseConv2D False\n",
      "76 BatchNormalization False\n",
      "77 ReLU False\n",
      "78 Conv2D False\n",
      "79 BatchNormalization False\n",
      "80 ReLU False\n",
      "81 DepthwiseConv2D False\n",
      "82 BatchNormalization False\n",
      "83 ReLU False\n",
      "84 Conv2D False\n",
      "85 BatchNormalization False\n",
      "86 ReLU False\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import MobileNet\n",
    "\n",
    "# MobileNet was designed to work on 224 x 224 pixel input images sizes\n",
    "img_rows = 224\n",
    "img_cols = 224 \n",
    "\n",
    "# Re-loads the MobileNet model without the top or FC layers\n",
    "MobileNet = MobileNet(weights = 'imagenet', \n",
    "                 include_top = False, \n",
    "                 input_shape = (img_rows, img_cols, 3))\n",
    "\n",
    "# Here we freeze the last 4 layers \n",
    "# Layers are set to trainable as True by default\n",
    "for layer in MobileNet.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Let's print our layers \n",
    "for (i,layer) in enumerate(MobileNet.layers):\n",
    "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's make a function that returns our FC Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTopModel(bottom_model, num_classes):\n",
    "    \"\"\"creates the top or head of the model that will be \n",
    "    placed ontop of the bottom layers\"\"\"\n",
    "\n",
    "    top_model = bottom_model.output\n",
    "    top_model = GlobalAveragePooling2D()(top_model)\n",
    "    top_model = Dense(1024,activation='relu')(top_model)\n",
    "    top_model = Dense(1024,activation='relu')(top_model)\n",
    "    top_model = Dense(512,activation='relu')(top_model)\n",
    "    top_model = Dense(num_classes,activation='softmax')(top_model)\n",
    "    return top_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's add our FC Head back onto VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "softmax() got an unexpected keyword argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-34b39fbb66e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m17\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mFC_Head\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maddTopModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMobileNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMobileNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFC_Head\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-60abd08aef3d>\u001b[0m in \u001b[0;36maddTopModel\u001b[0;34m(bottom_model, num_classes)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtop_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtop_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtop_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtop_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.6/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'channels_last'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.6/site-packages/keras/activations.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(x, axis)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot apply softmax to a tensor that is 1D'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(x, axis)\u001b[0m\n\u001b[1;32m   3229\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3230\u001b[0m     \"\"\"\n\u001b[0;32m-> 3231\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: softmax() got an unexpected keyword argument 'axis'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "num_classes = 17\n",
    "\n",
    "FC_Head = addTopModel(MobileNet, num_classes)\n",
    "\n",
    "model = Model(inputs=MobileNet.input, outputs=FC_Head)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading our ASL Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1190 images belonging to 17 classes.\n",
      "Found 170 images belonging to 17 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_dir = './17_flowers/train'\n",
    "validation_data_dir = './17_flowers/validation'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=20,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    " \n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "# Change the batchsize according to your system RAM\n",
    "train_batchsize = 16\n",
    "val_batchsize = 10\n",
    " \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=train_batchsize,\n",
    "        class_mode='categorical')\n",
    " \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=val_batchsize,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# Note we use a very small learning rate \n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = RMSprop(lr = 0.001),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "74/74 [==============================] - 119s 2s/step - loss: 0.7113 - acc: 0.8111 - val_loss: 2.2716 - val_acc: 0.5600\n",
      "Epoch 2/15\n",
      "74/74 [==============================] - 116s 2s/step - loss: 0.5406 - acc: 0.8514 - val_loss: 0.8844 - val_acc: 0.7500\n",
      "Epoch 3/15\n",
      "74/74 [==============================] - 155s 2s/step - loss: 0.5591 - acc: 0.8407 - val_loss: 1.0699 - val_acc: 0.7400\n",
      "Epoch 4/15\n",
      "74/74 [==============================] - 215s 3s/step - loss: 0.5176 - acc: 0.8640 - val_loss: 1.3874 - val_acc: 0.7400\n",
      "Epoch 5/15\n",
      "74/74 [==============================] - 214s 3s/step - loss: 0.5215 - acc: 0.8714 - val_loss: 2.9774 - val_acc: 0.5900\n",
      "Epoch 6/15\n",
      "74/74 [==============================] - 218s 3s/step - loss: 0.3482 - acc: 0.9088 - val_loss: 2.8696 - val_acc: 0.6300\n",
      "Epoch 7/15\n",
      "74/74 [==============================] - 214s 3s/step - loss: 0.4248 - acc: 0.9003 - val_loss: 0.5094 - val_acc: 0.8800\n",
      "Epoch 8/15\n",
      "74/74 [==============================] - 208s 3s/step - loss: 0.4008 - acc: 0.9096 - val_loss: 2.1466 - val_acc: 0.7100\n",
      "Epoch 9/15\n",
      "74/74 [==============================] - 206s 3s/step - loss: 0.3946 - acc: 0.9113 - val_loss: 0.6692 - val_acc: 0.8600\n",
      "Epoch 10/15\n",
      "74/74 [==============================] - 203s 3s/step - loss: 0.3517 - acc: 0.9155 - val_loss: 0.9865 - val_acc: 0.8400\n",
      "Epoch 11/15\n",
      "74/74 [==============================] - 235s 3s/step - loss: 0.4103 - acc: 0.9198 - val_loss: 2.9012 - val_acc: 0.7000\n",
      "Epoch 12/15\n",
      "74/74 [==============================] - 260s 4s/step - loss: 0.3570 - acc: 0.9296 - val_loss: 1.4848 - val_acc: 0.7500\n",
      "Epoch 13/15\n",
      "74/74 [==============================] - 240s 3s/step - loss: 0.4102 - acc: 0.9158 - val_loss: 0.7908 - val_acc: 0.8200\n",
      "Epoch 14/15\n",
      "74/74 [==============================] - 213s 3s/step - loss: 0.3580 - acc: 0.9207 - val_loss: 1.1088 - val_acc: 0.8500\n",
      "Epoch 15/15\n",
      "74/74 [==============================] - 209s 3s/step - loss: 0.3497 - acc: 0.9265 - val_loss: 2.7720 - val_acc: 0.7400\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9a863078ecc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Evaluate the performance of our trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "nb_train_samples = 1190\n",
    "nb_validation_samples = 170\n",
    "epochs = 15\n",
    "batch_size = 16\n",
    "\n",
    "#history = model.fit(x_train, y_train,\n",
    "#          batch_size=batch_size,\n",
    "#          epochs=epochs,\n",
    "#          validation_data=(x_test, y_test),\n",
    "#          shuffle=True)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = nb_train_samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = nb_validation_samples // batch_size)\n",
    "\n",
    "model.save(\"/home/deeplearningcv/DeepLearningCV/Trained Models/mobileNet_vgg.h5\")\n",
    "\n",
    "# Evaluate the performance of our trained model\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
