{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using MobileNet for our Monkey Classifer\n",
    "\n",
    "### Loading the MobileNet Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze all layers except the top 4, as we'll only be training the top 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer False\n",
      "1 ZeroPadding2D False\n",
      "2 Conv2D False\n",
      "3 BatchNormalization False\n",
      "4 ReLU False\n",
      "5 DepthwiseConv2D False\n",
      "6 BatchNormalization False\n",
      "7 ReLU False\n",
      "8 Conv2D False\n",
      "9 BatchNormalization False\n",
      "10 ReLU False\n",
      "11 ZeroPadding2D False\n",
      "12 DepthwiseConv2D False\n",
      "13 BatchNormalization False\n",
      "14 ReLU False\n",
      "15 Conv2D False\n",
      "16 BatchNormalization False\n",
      "17 ReLU False\n",
      "18 DepthwiseConv2D False\n",
      "19 BatchNormalization False\n",
      "20 ReLU False\n",
      "21 Conv2D False\n",
      "22 BatchNormalization False\n",
      "23 ReLU False\n",
      "24 ZeroPadding2D False\n",
      "25 DepthwiseConv2D False\n",
      "26 BatchNormalization False\n",
      "27 ReLU False\n",
      "28 Conv2D False\n",
      "29 BatchNormalization False\n",
      "30 ReLU False\n",
      "31 DepthwiseConv2D False\n",
      "32 BatchNormalization False\n",
      "33 ReLU False\n",
      "34 Conv2D False\n",
      "35 BatchNormalization False\n",
      "36 ReLU False\n",
      "37 ZeroPadding2D False\n",
      "38 DepthwiseConv2D False\n",
      "39 BatchNormalization False\n",
      "40 ReLU False\n",
      "41 Conv2D False\n",
      "42 BatchNormalization False\n",
      "43 ReLU False\n",
      "44 DepthwiseConv2D False\n",
      "45 BatchNormalization False\n",
      "46 ReLU False\n",
      "47 Conv2D False\n",
      "48 BatchNormalization False\n",
      "49 ReLU False\n",
      "50 DepthwiseConv2D False\n",
      "51 BatchNormalization False\n",
      "52 ReLU False\n",
      "53 Conv2D False\n",
      "54 BatchNormalization False\n",
      "55 ReLU False\n",
      "56 DepthwiseConv2D False\n",
      "57 BatchNormalization False\n",
      "58 ReLU False\n",
      "59 Conv2D False\n",
      "60 BatchNormalization False\n",
      "61 ReLU False\n",
      "62 DepthwiseConv2D False\n",
      "63 BatchNormalization False\n",
      "64 ReLU False\n",
      "65 Conv2D False\n",
      "66 BatchNormalization False\n",
      "67 ReLU False\n",
      "68 DepthwiseConv2D False\n",
      "69 BatchNormalization False\n",
      "70 ReLU False\n",
      "71 Conv2D False\n",
      "72 BatchNormalization False\n",
      "73 ReLU False\n",
      "74 ZeroPadding2D False\n",
      "75 DepthwiseConv2D False\n",
      "76 BatchNormalization False\n",
      "77 ReLU False\n",
      "78 Conv2D False\n",
      "79 BatchNormalization False\n",
      "80 ReLU False\n",
      "81 DepthwiseConv2D False\n",
      "82 BatchNormalization False\n",
      "83 ReLU False\n",
      "84 Conv2D False\n",
      "85 BatchNormalization False\n",
      "86 ReLU False\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import MobileNet\n",
    "\n",
    "# MobileNet was designed to work on 224 x 224 pixel input images sizes\n",
    "img_rows, img_cols = 224, 224 \n",
    "\n",
    "# Re-loads the MobileNet model without the top or FC layers\n",
    "MobileNet = MobileNet(weights = 'imagenet', \n",
    "                 include_top = False, \n",
    "                 input_shape = (img_rows, img_cols, 3))\n",
    "\n",
    "# Here we freeze the last 4 layers \n",
    "# Layers are set to trainable as True by default\n",
    "for layer in MobileNet.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Let's print our layers \n",
    "for (i,layer) in enumerate(MobileNet.layers):\n",
    "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's make a function that returns our FC Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTopModel(bottom_model, num_classes):\n",
    "    \"\"\"creates the top or head of the model that will be \n",
    "    placed ontop of the bottom layers\"\"\"\n",
    "\n",
    "    top_model = bottom_model.output\n",
    "    top_model = GlobalAveragePooling2D()(top_model)\n",
    "    top_model = Dense(1024,activation='relu')(top_model)\n",
    "    top_model = Dense(1024,activation='relu')(top_model)\n",
    "    top_model = Dense(512,activation='relu')(top_model)\n",
    "    top_model = Dense(num_classes,activation='softmax')(top_model)\n",
    "    return top_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's add our FC Head back onto MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 81)                41553     \n",
      "=================================================================\n",
      "Total params: 5,894,417\n",
      "Trainable params: 2,665,553\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "# Set our class number to 81 (81 Fruit Classes in Dataset)\n",
    "num_classes = 81\n",
    "\n",
    "FC_Head = addTopModel(MobileNet, num_classes)\n",
    "\n",
    "model = Model(inputs=MobileNet.input, outputs=FC_Head)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading our Monkey Breed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41322 images belonging to 81 classes.\n",
      "Found 13877 images belonging to 81 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_dir = './fruits-360/train'\n",
    "validation_data_dir = './fruits-360/validation'\n",
    "\n",
    "# Let's use some data augmentaiton \n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=30,\n",
    "      width_shift_range=0.3,\n",
    "      height_shift_range=0.3,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    " \n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "# set our batch size (typically on most mid tier systems we'll use 16-32)\n",
    "batch_size = 32\n",
    " \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    " \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2582/2582 [==============================] - 17951s 7s/step - loss: 15.9214 - acc: 0.0119 - val_loss: 15.9145 - val_acc: 0.0120\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 15.91453, saving model to /home/deeplearningcv/DeepLearningCV/Trained Models/monkey_breed_mobileNet.h5\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "                     \n",
    "checkpoint = ModelCheckpoint(\"/home/deeplearningcv/DeepLearningCV/Trained Models/monkey_breed_mobileNet.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 3,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop, checkpoint]\n",
    "\n",
    "# We use a very small learning rate \n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = RMSprop(lr = 0.001),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "nb_train_samples = 41322\n",
    "nb_validation_samples = 13877\n",
    "epochs = 1\n",
    "batch_size = 16\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = nb_train_samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "Display = True\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "classifier = load_model('/home/deeplearningcv/DeepLearningCV/Trained Models/monkey_breed_mobileNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class - n6\n",
      "./monkey_breed/validation/n6/n616.jpg\n",
      "[[8.0425608e-08 1.9859501e-06 2.1087038e-07 3.1327550e-06 1.1404579e-06\n",
      "  2.3951327e-05 9.9995279e-01 2.5560851e-06 2.2850985e-07 1.3979495e-05]]\n",
      "366\n",
      "Class - n7\n",
      "./monkey_breed/validation/n7/n700.jpg\n",
      "[[0.00544843 0.02220409 0.02095839 0.00321412 0.00545697 0.06743879\n",
      "  0.00922247 0.7674949  0.06986954 0.02869224]]\n",
      "1200\n",
      "Class - n8\n",
      "./monkey_breed/validation/n8/n8011.jpg\n",
      "[[9.9283481e-01 1.1999028e-05 3.4330957e-04 5.4160839e-05 5.7375550e-05\n",
      "  2.7149179e-04 6.1488236e-06 8.6563472e-05 3.6265836e-03 2.7075980e-03]]\n",
      "280\n",
      "Class - n9\n",
      "./monkey_breed/validation/n9/n9010.jpg\n",
      "[[2.0826825e-07 3.3281124e-06 5.6709819e-06 9.9993563e-01 3.9807546e-07\n",
      "  6.1036958e-06 6.9685721e-06 1.8068430e-07 1.8776193e-07 4.1326959e-05]]\n",
      "311\n",
      "Class - n8\n",
      "./monkey_breed/validation/n8/n800.jpg\n",
      "[[8.8824545e-06 2.4828432e-06 5.3284484e-06 1.6121263e-06 1.2632455e-06\n",
      "  9.9917509e-07 4.9166840e-07 9.2215974e-05 9.9987304e-01 1.3764198e-05]]\n",
      "397\n",
      "Class - n8\n",
      "./monkey_breed/validation/n8/n8013.jpg\n",
      "[[3.0548932e-07 1.0771314e-07 2.2524125e-07 8.8826447e-08 5.3401255e-08\n",
      "  2.8955728e-08 1.5302549e-08 3.7822088e-06 9.9999464e-01 6.6076882e-07]]\n",
      "394\n",
      "Class - n6\n",
      "./monkey_breed/validation/n6/n607.jpg\n",
      "[[8.6338798e-05 2.6068505e-04 5.9049285e-04 1.5234015e-03 4.6377274e-04\n",
      "  4.1457010e-03 9.9182022e-01 2.1548079e-04 1.4214146e-04 7.5183291e-04]]\n",
      "298\n",
      "Class - n4\n",
      "./monkey_breed/validation/n4/n402.jpg\n",
      "[[4.3671741e-04 5.0642836e-04 2.5254507e-03 9.9212127e-03 9.8222971e-01\n",
      "  3.2538190e-04 1.9580990e-03 9.8609424e-04 7.9143402e-04 3.1956960e-04]]\n",
      "718\n",
      "Class - n5\n",
      "./monkey_breed/validation/n5/n514.jpg\n",
      "[[1.4196063e-02 1.4517434e-04 9.6027664e-04 8.4554762e-05 1.2992063e-04\n",
      "  9.1436845e-01 3.5353075e-04 2.5568856e-04 2.0412562e-04 6.9302283e-02]]\n",
      "360\n",
      "Class - n2\n",
      "./monkey_breed/validation/n2/n208.jpg\n",
      "[[2.9148665e-04 5.7164707e-06 9.8741305e-01 1.2012684e-02 3.0835090e-05\n",
      "  1.1630219e-04 1.7983275e-05 5.9565486e-06 1.5036770e-05 9.1010814e-05]]\n",
      "1900\n"
     ]
    }
   ],
   "source": [
    "def draw_test(name, pred, im):\n",
    "    BLACK = [0,0,0]\n",
    "    print(im.shape[0])\n",
    "    expanded_image = cv2.copyMakeBorder(im, 0, 0, 0, input_im.shape[0] ,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    cv2.putText(expanded_image, str(pred), (52, 70) , cv2.FONT_HERSHEY_COMPLEX_SMALL,4, (0,255,0), 2)\n",
    "    cv2.imshow(name, expanded_image)\n",
    "\n",
    "def getRandomImage():\n",
    "    path = './monkey_breed/validation/'\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "    random_directory = np.random.randint(0,len(folders))\n",
    "    path_class = folders[random_directory]\n",
    "    print(\"Class - \" + str(path_class))\n",
    "    file_path = path + path_class\n",
    "\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    print(file_path+\"/\"+image_name)\n",
    "    return cv2.imread(file_path+\"/\"+image_name)    \n",
    "\n",
    "for i in range(0,10):\n",
    "    input_im = getRandomImage()\n",
    "    input_original = input_im.copy()\n",
    "    input_im = cv2.resize(input_im, (224, 224), interpolation = cv2.INTER_LINEAR)\n",
    "    cv2.imshow(\"Test Image\", input_im)\n",
    "    input_im = input_im / 255.\n",
    "    input_im = input_im.reshape(1,224,224,3) \n",
    "    \n",
    "    ## Get Prediction\n",
    "    print(classifier.predict(input_im, 1, verbose = 0))\n",
    "    res = np.argmax(classifier.predict(input_im, 1, verbose = 0), axis=1)\n",
    "\n",
    "    draw_test(\"Prediction\", res, input_original) \n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object walk at 0x7f003c0f18e0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.walk(\"./monkey_breed/validation/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n8', 'n2', 'n1', 'n4', 'n9', 'n0', 'n7', 'n6', 'n5', 'n3']\n",
      "n0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = './monkey_breed/validation/'\n",
    "folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "print(folders)\n",
    "\n",
    "random_directory = np.random.randint(0,len(folders))\n",
    "print(folders[random_directory])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class - 9\n",
      "./monkey_breed/validation/n3/n3010.jpg\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "\n",
    "def getRandomImage():\n",
    "    path = './monkey_breed/validation/'\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "    random_directory = np.random.randint(0,len(folders))\n",
    "    print(\"Class - \" + str(random_directory))\n",
    "    path_class = folders[random_directory]\n",
    "    file_path = path + path_class\n",
    "\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    print(file_path+\"/\"+image_name)\n",
    "    return cv2.imread(file_path+\"/\"+image_name)\n",
    "\n",
    "image = getRandomImage()\n",
    "cv2.imshow(\"test\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41322 images belonging to 81 classes.\n",
      "Found 13877 images belonging to 81 classes.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "\n",
    "num_classes = 81\n",
    "img_rows, img_cols = 32, 32\n",
    "batch_size = 16\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_dir = './fruits-360/train'\n",
    "validation_data_dir = './fruits-360/validation'\n",
    "\n",
    "# Let's use some data augmentaiton \n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=30,\n",
    "      width_shift_range=0.3,\n",
    "      height_shift_range=0.3,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    " \n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    " \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 81)                41553     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 81)                0         \n",
      "=================================================================\n",
      "Total params: 1,287,281\n",
      "Trainable params: 1,287,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# Padding = 'same'  results in padding the input such that\n",
    "# the output has the same length as the original input\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape= (img_rows, img_cols, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer and configure some parameters\n",
    "#opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2582/2582 [==============================] - 269s 104ms/step - loss: 1.7532 - acc: 0.4740 - val_loss: 0.5560 - val_acc: 0.8069\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.55598, saving model to /home/deeplearningcv/DeepLearningCV/Trained Models/fruits_fresh_cnn.h5\n",
      "Epoch 2/5\n",
      "2582/2582 [==============================] - 262s 101ms/step - loss: 0.6594 - acc: 0.7921 - val_loss: 0.4869 - val_acc: 0.8577\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.55598 to 0.48694, saving model to /home/deeplearningcv/DeepLearningCV/Trained Models/fruits_fresh_cnn.h5\n",
      "Epoch 3/5\n",
      "2582/2582 [==============================] - 206s 80ms/step - loss: 0.5250 - acc: 0.8455 - val_loss: 0.2939 - val_acc: 0.9148\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.48694 to 0.29386, saving model to /home/deeplearningcv/DeepLearningCV/Trained Models/fruits_fresh_cnn.h5\n",
      "Epoch 4/5\n",
      "2582/2582 [==============================] - 263s 102ms/step - loss: 0.5116 - acc: 0.8599 - val_loss: 0.3469 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.29386\n",
      "Epoch 5/5\n",
      "2582/2582 [==============================] - 275s 106ms/step - loss: 0.5639 - acc: 0.8580 - val_loss: 0.6419 - val_acc: 0.8394\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.29386\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "                     \n",
    "checkpoint = ModelCheckpoint(\"/home/deeplearningcv/DeepLearningCV/Trained Models/fruits_fresh_cnn.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 3,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop, checkpoint]\n",
    "\n",
    "# We use a very small learning rate \n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = RMSprop(lr = 0.001),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "nb_train_samples = 41322\n",
    "nb_validation_samples = 13877\n",
    "epochs = 5\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = nb_train_samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[136   0   0 ...   0   0  21]\n",
      " [ 21 137   0 ...   0   0   0]\n",
      " [  0  21  68 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ... 143   0   0]\n",
      " [  0   0   0 ...  21 106   0]\n",
      " [  0   0   0 ...   0  21 228]]\n",
      "Classification Report\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "     Apple Braeburn       0.49      0.83      0.61       164\n",
      "     Apple Golden 1       0.82      0.84      0.83       164\n",
      "     Apple Golden 2       0.69      0.41      0.52       164\n",
      "     Apple Golden 3       0.56      0.97      0.71       161\n",
      " Apple Granny Smith       0.58      0.87      0.70       164\n",
      "        Apple Red 1       0.71      0.84      0.77       164\n",
      "        Apple Red 2       0.94      0.60      0.73       164\n",
      "        Apple Red 3       0.82      0.85      0.84       144\n",
      "Apple Red Delicious       0.87      0.87      0.87       166\n",
      "   Apple Red Yellow       0.80      0.78      0.79       164\n",
      "            Apricot       0.56      0.87      0.68       164\n",
      "            Avocado       0.88      0.48      0.62       143\n",
      "       Avocado ripe       0.87      0.87      0.87       166\n",
      "             Banana       0.72      0.63      0.67       166\n",
      "         Banana Red       0.44      0.80      0.57       166\n",
      "       Cactus fruit       0.52      0.56      0.54       166\n",
      "       Cantaloupe 1       0.87      0.87      0.87       164\n",
      "       Cantaloupe 2       0.89      0.87      0.88       164\n",
      "          Carambula       0.63      0.68      0.65       166\n",
      "           Cherry 1       0.52      0.87      0.65       164\n",
      "           Cherry 2       1.00      0.28      0.44       246\n",
      "     Cherry Rainier       0.90      0.80      0.85       246\n",
      "   Cherry Wax Black       0.87      0.87      0.87       164\n",
      "     Cherry Wax Red       0.86      0.81      0.84       164\n",
      "  Cherry Wax Yellow       0.87      0.87      0.87       164\n",
      "         Clementine       0.95      0.83      0.88       166\n",
      "              Cocos       0.87      0.87      0.87       166\n",
      "              Dates       0.87      0.87      0.87       166\n",
      "         Granadilla       0.55      0.83      0.66       166\n",
      "         Grape Pink       0.87      0.87      0.87       164\n",
      "        Grape White       0.87      0.87      0.87       166\n",
      "      Grape White 2       0.86      0.77      0.82       166\n",
      "    Grapefruit Pink       0.85      0.74      0.79       166\n",
      "   Grapefruit White       0.96      0.26      0.41       164\n",
      "              Guava       0.96      0.66      0.78       166\n",
      "        Huckleberry       0.87      0.87      0.87       166\n",
      "               Kaki       0.73      0.87      0.79       166\n",
      "               Kiwi       0.76      0.33      0.46       156\n",
      "           Kumquats       1.00      0.54      0.70       166\n",
      "              Lemon       0.51      0.76      0.61       164\n",
      "        Lemon Meyer       0.87      0.87      0.87       166\n",
      "              Limes       0.86      0.80      0.83       166\n",
      "             Lychee       0.87      0.87      0.87       166\n",
      "          Mandarine       1.00      0.22      0.36       166\n",
      "              Mango       0.87      0.87      0.87       166\n",
      "           Maracuja       0.86      0.75      0.80       166\n",
      " Melon Piel de Sapo       0.85      0.91      0.88       246\n",
      "           Mulberry       0.87      0.87      0.87       164\n",
      "          Nectarine       0.80      0.70      0.75       164\n",
      "             Orange       0.73      0.32      0.44       160\n",
      "             Papaya       0.63      0.65      0.64       164\n",
      "      Passion Fruit       0.87      0.87      0.87       166\n",
      "              Peach       0.52      0.77      0.62       164\n",
      "         Peach Flat       0.43      0.87      0.57       164\n",
      "               Pear       0.72      0.87      0.79       164\n",
      "         Pear Abate       0.34      0.82      0.48       166\n",
      "       Pear Monster       0.86      0.77      0.81       166\n",
      "      Pear Williams       0.83      0.41      0.55       166\n",
      "             Pepino       0.76      0.63      0.69       166\n",
      "           Physalis       0.87      0.87      0.87       164\n",
      " Physalis with Husk       0.87      0.29      0.44       164\n",
      "          Pineapple       0.89      0.70      0.79       166\n",
      "     Pineapple Mini       0.97      0.21      0.34       163\n",
      "       Pitahaya Red       0.87      0.86      0.86       166\n",
      "               Plum       0.82      0.85      0.84       151\n",
      "        Pomegranate       0.35      0.37      0.36       164\n",
      "             Quince       0.87      0.87      0.87       166\n",
      "           Rambutan       0.87      0.87      0.87       164\n",
      "          Raspberry       0.87      0.87      0.87       166\n",
      "              Salak       0.46      0.31      0.37       162\n",
      "         Strawberry       0.64      0.87      0.74       164\n",
      "   Strawberry Wedge       0.93      0.85      0.89       246\n",
      "          Tamarillo       0.82      0.87      0.85       166\n",
      "            Tangelo       0.80      0.87      0.84       166\n",
      "           Tomato 1       0.85      0.91      0.88       246\n",
      "           Tomato 2       0.89      0.73      0.80       225\n",
      "           Tomato 3       0.57      0.91      0.70       246\n",
      "           Tomato 4       1.00      0.31      0.47       160\n",
      "  Tomato Cherry Red       0.87      0.87      0.87       164\n",
      "      Tomato Maroon       0.83      0.83      0.83       127\n",
      "             Walnut       0.92      0.92      0.92       249\n",
      "\n",
      "          micro avg       0.74      0.74      0.74     13877\n",
      "          macro avg       0.78      0.74      0.73     13877\n",
      "       weighted avg       0.79      0.74      0.74     13877\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#Confution Matrix and Classification Report\n",
    "Y_pred = model.predict_generator(validation_generator, nb_validation_samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = list(class_labels.values())\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class - 1\n",
      "./fruits-360/validation/Kumquats/r_139_100.jpg\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def getRandomImage():\n",
    "    path = './fruits-360/validation/'\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "    random_directory = 1\n",
    "    print(\"Class - \" + str(random_directory))\n",
    "    path_class = folders[random_directory]\n",
    "    file_path = path + path_class\n",
    "\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    print(file_path+\"/\"+image_name)\n",
    "    return cv2.imread(file_path+\"/\"+image_name)\n",
    "\n",
    "image = getRandomImage()\n",
    "cv2.imshow(\"test\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import cv2\n",
    "import re\n",
    "\n",
    "path = './fruits-360/validation/'\n",
    "folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "keys =  list(range(0, 80))\n",
    "\n",
    "def get_dic_from_two_lists(keys, values):\n",
    "    return { keys[i] : values[i] for i in range(len(keys)) }\n",
    "\n",
    "fruits_dict = get_dic_from_two_lists(keys,folders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "classifier = load_model('/home/deeplearningcv/DeepLearningCV/Trained Models/fruits_fresh_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Class - ./fruits-360/validation/Clementine\n",
      "./fruits-360/validation/Clementine/66_100.jpg\n",
      "35 Huckleberry\n",
      "True Class - ./fruits-360/validation/Granadilla\n",
      "./fruits-360/validation/Granadilla/r_276_100.jpg\n",
      "35 Huckleberry\n",
      "True Class - ./fruits-360/validation/Apple Red 1\n",
      "./fruits-360/validation/Apple Red 1/r_8_100.jpg\n",
      "35 Huckleberry\n",
      "True Class - ./fruits-360/validation/Tamarillo\n",
      "./fruits-360/validation/Tamarillo/306_100.jpg\n",
      "27 Dates\n",
      "True Class - ./fruits-360/validation/Salak\n",
      "./fruits-360/validation/Salak/287_100.jpg\n",
      "27 Dates\n",
      "True Class - ./fruits-360/validation/Grape White 2\n",
      "./fruits-360/validation/Grape White 2/r_33_100.jpg\n",
      "12 Avocado ripe\n",
      "True Class - ./fruits-360/validation/Raspberry\n",
      "./fruits-360/validation/Raspberry/111_100.jpg\n",
      "63 Pitahaya Red\n",
      "True Class - ./fruits-360/validation/Mandarine\n",
      "./fruits-360/validation/Mandarine/210_100.jpg\n",
      "35 Huckleberry\n",
      "True Class - ./fruits-360/validation/Cherry Wax Red\n",
      "./fruits-360/validation/Cherry Wax Red/r_101_100.jpg\n",
      "35 Huckleberry\n",
      "True Class - ./fruits-360/validation/Nectarine\n",
      "./fruits-360/validation/Nectarine/r_71_100.jpg\n",
      "35 Huckleberry\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "\n",
    "def get_dic_from_two_lists(keys, values):\n",
    "    return { keys[i] : values[i] for i in range(len(keys)) }\n",
    "\n",
    "def draw_test(name, pred, im):\n",
    "    BLACK = [0,0,0]\n",
    "    expanded_image = cv2.copyMakeBorder(im, 80, 0, 0, 100 ,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    cv2.putText(expanded_image, pred, (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2)\n",
    "    cv2.imshow(name, expanded_image)\n",
    "\n",
    "def getRandomImage(path):\n",
    "    \"\"\"function loads a random images from a random folder in our test path \"\"\"\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "    random_directory = np.random.randint(0,len(folders))\n",
    "    path_class = folders[random_directory]\n",
    "    \n",
    "    file_path = path + path_class\n",
    "    print(\"True Class - \" + str(file_path))\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    print(file_path+\"/\"+image_name)\n",
    "    return cv2.imread(file_path+\"/\"+image_name)    \n",
    "\n",
    "path = './fruits-360/validation/' \n",
    "classes = validation_generator.class_indices\n",
    "class_labels = {v: k for k, v in classes.items()}\n",
    "\n",
    "for i in range(0,10):\n",
    "    input_im = getRandomImage(path)\n",
    "\n",
    "    input_original = input_im.copy()\n",
    "    input_original = cv2.resize(input_original, None, fx=2, fy=2, interpolation = cv2.INTER_LINEAR)\n",
    "    \n",
    "    input_im = cv2.resize(input_im, (32, 32), interpolation = cv2.INTER_LINEAR)\n",
    "    input_im = input_im * 1./255 \n",
    "    input_im = input_im.reshape(1,32,32,3) \n",
    "    \n",
    "    # Get Prediction\n",
    "    #res = np.argmax(classifier.predict(input_im, 1, verbose = 0), axis=1)\n",
    "    res = str(classifier.predict_classes(input_im, 1, verbose = 0)[0])\n",
    "    \n",
    "    fruit = class_labels[int(res)]\n",
    "    print(res, fruit)\n",
    "    \n",
    "    # Show image with predicted class\n",
    "    draw_test(\"Prediction\", fruit, input_original) \n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Class - Peach\n",
      "True Class - Tomato 3\n",
      "True Class - Apple Red Delicious\n",
      "True Class - Lemon\n",
      "True Class - Grape White 2\n",
      "True Class - Pineapple\n",
      "True Class - Apple Braeburn\n",
      "True Class - Cherry Rainier\n",
      "True Class - Tomato Maroon\n",
      "True Class - Cherry Wax Black\n",
      "Peach\n",
      "Tomato 3\n",
      "Apple Red Delicious\n",
      "Lemon\n",
      "Grape White 2\n",
      "Pineapple\n",
      "Apple Braeburn\n",
      "Cantaloupe 2\n",
      "Tomato Maroon\n",
      "Cherry Wax Black\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "\n",
    "def draw_test(name, pred, im, true_label):\n",
    "    BLACK = [0,0,0]\n",
    "    expanded_image = cv2.copyMakeBorder(im, 160, 0, 0, 300 ,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    cv2.putText(expanded_image, \"predited - \"+ pred, (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2)\n",
    "    cv2.putText(expanded_image, \"true - \"+ true_label, (20, 120) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)\n",
    "    cv2.imshow(name, expanded_image)\n",
    "\n",
    "\n",
    "def getRandomImage(path, img_width, img_height):\n",
    "    \"\"\"function loads a random images from a random folder in our test path \"\"\"\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "    random_directory = np.random.randint(0,len(folders))\n",
    "    path_class = folders[random_directory]\n",
    "    file_path = path + path_class\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    final_path = file_path + \"/\" + image_name\n",
    "    return image.load_img(final_path, target_size = (img_width, img_height)), final_path, path_class\n",
    "\n",
    "# dimensions of our images\n",
    "img_width, img_height = 32, 32\n",
    "\n",
    "#model = load_model('/home/deeplearningcv/DeepLearningCV/Trained Models/fruits_fresh_cnn.h5')\n",
    "\n",
    "# We use a very small learning rate \n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = RMSprop(lr = 0.001),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "files = []\n",
    "predictions = []\n",
    "true_labels = []\n",
    "# predicting images\n",
    "for i in range(0, 10):\n",
    "    path = './fruits-360/validation/' \n",
    "    img, final_path, true_label = getRandomImage(path, img_width, img_height)\n",
    "    files.append(final_path)\n",
    "    true_labels.append(true_label)\n",
    "    x = image.img_to_array(img)\n",
    "    x = x * 1./255\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    images = np.vstack([x])\n",
    "    classes = model.predict_classes(images, batch_size = 10)\n",
    "    predictions.append(classes)\n",
    "    \n",
    "for i in range(0, len(files)):\n",
    "    image = cv2.imread((files[i]))\n",
    "    draw_test(\"Prediction\", class_labels[predictions[i][0]], image, true_labels[i])\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
