{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using MobileNet for our Monkey Classifer\n",
    "\n",
    "### Loading the MobileNet Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze all layers except the top 4, as we'll only be training the top 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer False\n",
      "1 ZeroPadding2D False\n",
      "2 Conv2D False\n",
      "3 BatchNormalization False\n",
      "4 ReLU False\n",
      "5 DepthwiseConv2D False\n",
      "6 BatchNormalization False\n",
      "7 ReLU False\n",
      "8 Conv2D False\n",
      "9 BatchNormalization False\n",
      "10 ReLU False\n",
      "11 ZeroPadding2D False\n",
      "12 DepthwiseConv2D False\n",
      "13 BatchNormalization False\n",
      "14 ReLU False\n",
      "15 Conv2D False\n",
      "16 BatchNormalization False\n",
      "17 ReLU False\n",
      "18 DepthwiseConv2D False\n",
      "19 BatchNormalization False\n",
      "20 ReLU False\n",
      "21 Conv2D False\n",
      "22 BatchNormalization False\n",
      "23 ReLU False\n",
      "24 ZeroPadding2D False\n",
      "25 DepthwiseConv2D False\n",
      "26 BatchNormalization False\n",
      "27 ReLU False\n",
      "28 Conv2D False\n",
      "29 BatchNormalization False\n",
      "30 ReLU False\n",
      "31 DepthwiseConv2D False\n",
      "32 BatchNormalization False\n",
      "33 ReLU False\n",
      "34 Conv2D False\n",
      "35 BatchNormalization False\n",
      "36 ReLU False\n",
      "37 ZeroPadding2D False\n",
      "38 DepthwiseConv2D False\n",
      "39 BatchNormalization False\n",
      "40 ReLU False\n",
      "41 Conv2D False\n",
      "42 BatchNormalization False\n",
      "43 ReLU False\n",
      "44 DepthwiseConv2D False\n",
      "45 BatchNormalization False\n",
      "46 ReLU False\n",
      "47 Conv2D False\n",
      "48 BatchNormalization False\n",
      "49 ReLU False\n",
      "50 DepthwiseConv2D False\n",
      "51 BatchNormalization False\n",
      "52 ReLU False\n",
      "53 Conv2D False\n",
      "54 BatchNormalization False\n",
      "55 ReLU False\n",
      "56 DepthwiseConv2D False\n",
      "57 BatchNormalization False\n",
      "58 ReLU False\n",
      "59 Conv2D False\n",
      "60 BatchNormalization False\n",
      "61 ReLU False\n",
      "62 DepthwiseConv2D False\n",
      "63 BatchNormalization False\n",
      "64 ReLU False\n",
      "65 Conv2D False\n",
      "66 BatchNormalization False\n",
      "67 ReLU False\n",
      "68 DepthwiseConv2D False\n",
      "69 BatchNormalization False\n",
      "70 ReLU False\n",
      "71 Conv2D False\n",
      "72 BatchNormalization False\n",
      "73 ReLU False\n",
      "74 ZeroPadding2D False\n",
      "75 DepthwiseConv2D False\n",
      "76 BatchNormalization False\n",
      "77 ReLU False\n",
      "78 Conv2D False\n",
      "79 BatchNormalization False\n",
      "80 ReLU False\n",
      "81 DepthwiseConv2D False\n",
      "82 BatchNormalization False\n",
      "83 ReLU False\n",
      "84 Conv2D False\n",
      "85 BatchNormalization False\n",
      "86 ReLU False\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import MobileNet\n",
    "\n",
    "# MobileNet was designed to work on 224 x 224 pixel input images sizes\n",
    "img_rows, img_cols = 224, 224 \n",
    "\n",
    "# Re-loads the MobileNet model without the top or FC layers\n",
    "MobileNet = MobileNet(weights = 'imagenet', \n",
    "                 include_top = False, \n",
    "                 input_shape = (img_rows, img_cols, 3))\n",
    "\n",
    "# Here we freeze the last 4 layers \n",
    "# Layers are set to trainable as True by default\n",
    "for layer in MobileNet.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Let's print our layers \n",
    "for (i,layer) in enumerate(MobileNet.layers):\n",
    "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's make a function that returns our FC Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTopModel(bottom_model, num_classes):\n",
    "    \"\"\"creates the top or head of the model that will be \n",
    "    placed ontop of the bottom layers\"\"\"\n",
    "\n",
    "    top_model = bottom_model.output\n",
    "    top_model = GlobalAveragePooling2D()(top_model)\n",
    "    top_model = Dense(1024,activation='relu')(top_model)\n",
    "    top_model = Dense(1024,activation='relu')(top_model)\n",
    "    top_model = Dense(512,activation='relu')(top_model)\n",
    "    top_model = Dense(num_classes,activation='softmax')(top_model)\n",
    "    return top_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's add our FC Head back onto MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 81)                41553     \n",
      "=================================================================\n",
      "Total params: 5,894,417\n",
      "Trainable params: 2,665,553\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "# Set our class number to 81 (81 Fruit Classes in Dataset)\n",
    "num_classes = 81\n",
    "\n",
    "FC_Head = addTopModel(MobileNet, num_classes)\n",
    "\n",
    "model = Model(inputs=MobileNet.input, outputs=FC_Head)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading our Monkey Breed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41322 images belonging to 81 classes.\n",
      "Found 13877 images belonging to 81 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_dir = './fruits-360/train'\n",
    "validation_data_dir = './fruits-360/validation'\n",
    "\n",
    "# Let's use some data augmentaiton \n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=30,\n",
    "      width_shift_range=0.3,\n",
    "      height_shift_range=0.3,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    " \n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "# set our batch size (typically on most mid tier systems we'll use 16-32)\n",
    "batch_size = 32\n",
    " \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    " \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2582/2582 [==============================] - 17951s 7s/step - loss: 15.9214 - acc: 0.0119 - val_loss: 15.9145 - val_acc: 0.0120\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 15.91453, saving model to /home/deeplearningcv/DeepLearningCV/Trained Models/monkey_breed_mobileNet.h5\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "                     \n",
    "checkpoint = ModelCheckpoint(\"/home/deeplearningcv/DeepLearningCV/Trained Models/monkey_breed_mobileNet.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 3,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop, checkpoint]\n",
    "\n",
    "# We use a very small learning rate \n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = RMSprop(lr = 0.001),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "nb_train_samples = 41322\n",
    "nb_validation_samples = 13877\n",
    "epochs = 1\n",
    "batch_size = 16\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = nb_train_samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "Display = True\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "classifier = load_model('/home/deeplearningcv/DeepLearningCV/Trained Models/monkey_breed_mobileNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class - n6\n",
      "./monkey_breed/validation/n6/n616.jpg\n",
      "[[8.0425608e-08 1.9859501e-06 2.1087038e-07 3.1327550e-06 1.1404579e-06\n",
      "  2.3951327e-05 9.9995279e-01 2.5560851e-06 2.2850985e-07 1.3979495e-05]]\n",
      "366\n",
      "Class - n7\n",
      "./monkey_breed/validation/n7/n700.jpg\n",
      "[[0.00544843 0.02220409 0.02095839 0.00321412 0.00545697 0.06743879\n",
      "  0.00922247 0.7674949  0.06986954 0.02869224]]\n",
      "1200\n",
      "Class - n8\n",
      "./monkey_breed/validation/n8/n8011.jpg\n",
      "[[9.9283481e-01 1.1999028e-05 3.4330957e-04 5.4160839e-05 5.7375550e-05\n",
      "  2.7149179e-04 6.1488236e-06 8.6563472e-05 3.6265836e-03 2.7075980e-03]]\n",
      "280\n",
      "Class - n9\n",
      "./monkey_breed/validation/n9/n9010.jpg\n",
      "[[2.0826825e-07 3.3281124e-06 5.6709819e-06 9.9993563e-01 3.9807546e-07\n",
      "  6.1036958e-06 6.9685721e-06 1.8068430e-07 1.8776193e-07 4.1326959e-05]]\n",
      "311\n",
      "Class - n8\n",
      "./monkey_breed/validation/n8/n800.jpg\n",
      "[[8.8824545e-06 2.4828432e-06 5.3284484e-06 1.6121263e-06 1.2632455e-06\n",
      "  9.9917509e-07 4.9166840e-07 9.2215974e-05 9.9987304e-01 1.3764198e-05]]\n",
      "397\n",
      "Class - n8\n",
      "./monkey_breed/validation/n8/n8013.jpg\n",
      "[[3.0548932e-07 1.0771314e-07 2.2524125e-07 8.8826447e-08 5.3401255e-08\n",
      "  2.8955728e-08 1.5302549e-08 3.7822088e-06 9.9999464e-01 6.6076882e-07]]\n",
      "394\n",
      "Class - n6\n",
      "./monkey_breed/validation/n6/n607.jpg\n",
      "[[8.6338798e-05 2.6068505e-04 5.9049285e-04 1.5234015e-03 4.6377274e-04\n",
      "  4.1457010e-03 9.9182022e-01 2.1548079e-04 1.4214146e-04 7.5183291e-04]]\n",
      "298\n",
      "Class - n4\n",
      "./monkey_breed/validation/n4/n402.jpg\n",
      "[[4.3671741e-04 5.0642836e-04 2.5254507e-03 9.9212127e-03 9.8222971e-01\n",
      "  3.2538190e-04 1.9580990e-03 9.8609424e-04 7.9143402e-04 3.1956960e-04]]\n",
      "718\n",
      "Class - n5\n",
      "./monkey_breed/validation/n5/n514.jpg\n",
      "[[1.4196063e-02 1.4517434e-04 9.6027664e-04 8.4554762e-05 1.2992063e-04\n",
      "  9.1436845e-01 3.5353075e-04 2.5568856e-04 2.0412562e-04 6.9302283e-02]]\n",
      "360\n",
      "Class - n2\n",
      "./monkey_breed/validation/n2/n208.jpg\n",
      "[[2.9148665e-04 5.7164707e-06 9.8741305e-01 1.2012684e-02 3.0835090e-05\n",
      "  1.1630219e-04 1.7983275e-05 5.9565486e-06 1.5036770e-05 9.1010814e-05]]\n",
      "1900\n"
     ]
    }
   ],
   "source": [
    "def draw_test(name, pred, im):\n",
    "    BLACK = [0,0,0]\n",
    "    print(im.shape[0])\n",
    "    expanded_image = cv2.copyMakeBorder(im, 0, 0, 0, input_im.shape[0] ,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    cv2.putText(expanded_image, str(pred), (52, 70) , cv2.FONT_HERSHEY_COMPLEX_SMALL,4, (0,255,0), 2)\n",
    "    cv2.imshow(name, expanded_image)\n",
    "\n",
    "def getRandomImage():\n",
    "    path = './monkey_breed/validation/'\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "    random_directory = np.random.randint(0,len(folders))\n",
    "    path_class = folders[random_directory]\n",
    "    print(\"Class - \" + str(path_class))\n",
    "    file_path = path + path_class\n",
    "\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    print(file_path+\"/\"+image_name)\n",
    "    return cv2.imread(file_path+\"/\"+image_name)    \n",
    "\n",
    "for i in range(0,10):\n",
    "    input_im = getRandomImage()\n",
    "    input_original = input_im.copy()\n",
    "    input_im = cv2.resize(input_im, (224, 224), interpolation = cv2.INTER_LINEAR)\n",
    "    cv2.imshow(\"Test Image\", input_im)\n",
    "    input_im = input_im / 255.\n",
    "    input_im = input_im.reshape(1,224,224,3) \n",
    "    \n",
    "    ## Get Prediction\n",
    "    print(classifier.predict(input_im, 1, verbose = 0))\n",
    "    res = np.argmax(classifier.predict(input_im, 1, verbose = 0), axis=1)\n",
    "\n",
    "    draw_test(\"Prediction\", res, input_original) \n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object walk at 0x7f003c0f18e0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.walk(\"./monkey_breed/validation/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n8', 'n2', 'n1', 'n4', 'n9', 'n0', 'n7', 'n6', 'n5', 'n3']\n",
      "n0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = './monkey_breed/validation/'\n",
    "folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "print(folders)\n",
    "\n",
    "random_directory = np.random.randint(0,len(folders))\n",
    "print(folders[random_directory])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class - 9\n",
      "./monkey_breed/validation/n3/n3010.jpg\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "\n",
    "def getRandomImage():\n",
    "    path = './monkey_breed/validation/'\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "    random_directory = np.random.randint(0,len(folders))\n",
    "    print(\"Class - \" + str(random_directory))\n",
    "    path_class = folders[random_directory]\n",
    "    file_path = path + path_class\n",
    "\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    print(file_path+\"/\"+image_name)\n",
    "    return cv2.imread(file_path+\"/\"+image_name)\n",
    "\n",
    "image = getRandomImage()\n",
    "cv2.imshow(\"test\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41322 images belonging to 81 classes.\n",
      "Found 13877 images belonging to 81 classes.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "\n",
    "num_classes = 81\n",
    "img_rows, img_cols = 32, 32\n",
    "batch_size = 16\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_dir = './fruits-360/train'\n",
    "validation_data_dir = './fruits-360/validation'\n",
    "\n",
    "# Let's use some data augmentaiton \n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=30,\n",
    "      width_shift_range=0.3,\n",
    "      height_shift_range=0.3,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    " \n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    " \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 81)                41553     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 81)                0         \n",
      "=================================================================\n",
      "Total params: 1,287,281\n",
      "Trainable params: 1,287,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# Padding = 'same'  results in padding the input such that\n",
    "# the output has the same length as the original input\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape= (img_rows, img_cols, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer and configure some parameters\n",
    "#opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2582/2582 [==============================] - 285s 110ms/step - loss: 1.7170 - acc: 0.4785 - val_loss: 0.7575 - val_acc: 0.7406\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.75749, saving model to /home/deeplearningcv/DeepLearningCV/Trained Models/fruits_fresh_cnn.h5\n",
      "Epoch 2/3\n",
      "2582/2582 [==============================] - 273s 106ms/step - loss: 0.6816 - acc: 0.7844 - val_loss: 0.2960 - val_acc: 0.9037\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.75749 to 0.29603, saving model to /home/deeplearningcv/DeepLearningCV/Trained Models/fruits_fresh_cnn.h5\n",
      "Epoch 3/3\n",
      "2582/2582 [==============================] - 270s 104ms/step - loss: 0.5459 - acc: 0.8413 - val_loss: 0.2805 - val_acc: 0.9247\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.29603 to 0.28051, saving model to /home/deeplearningcv/DeepLearningCV/Trained Models/fruits_fresh_cnn.h5\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "                     \n",
    "checkpoint = ModelCheckpoint(\"/home/deeplearningcv/DeepLearningCV/Trained Models/fruits_fresh_cnn.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 3,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop, checkpoint]\n",
    "\n",
    "# We use a very small learning rate \n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = RMSprop(lr = 0.001),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "nb_train_samples = 41322\n",
    "nb_validation_samples = 13877\n",
    "epochs = 3\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = nb_train_samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class - 1\n",
      "./fruits-360/validation/Kumquats/r_139_100.jpg\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def getRandomImage():\n",
    "    path = './fruits-360/validation/'\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "    random_directory = 1\n",
    "    print(\"Class - \" + str(random_directory))\n",
    "    path_class = folders[random_directory]\n",
    "    file_path = path + path_class\n",
    "\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    print(file_path+\"/\"+image_name)\n",
    "    return cv2.imread(file_path+\"/\"+image_name)\n",
    "\n",
    "image = getRandomImage()\n",
    "cv2.imshow(\"test\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import cv2\n",
    "import re\n",
    "\n",
    "path = './fruits-360/validation/'\n",
    "folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "keys =  list(range(0, 80))\n",
    "\n",
    "def get_dic_from_two_lists(keys, values):\n",
    "    return { keys[i] : values[i] for i in range(len(keys)) }\n",
    "\n",
    "fruits_dict = get_dic_from_two_lists(keys,folders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "classifier = load_model('/home/deeplearningcv/DeepLearningCV/Trained Models/fruits_fresh_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Class - ./fruits-360/train/Cantaloupe 1\n",
      "47 Kiwi\n",
      "True Class - ./fruits-360/train/Kiwi\n",
      "35 Cactus fruit\n",
      "True Class - ./fruits-360/train/Guava\n",
      "41 Pomegranate\n",
      "True Class - ./fruits-360/train/Maracuja\n",
      "47 Kiwi\n",
      "True Class - ./fruits-360/train/Apple Red 3\n",
      "35 Cactus fruit\n",
      "True Class - ./fruits-360/train/Apricot\n",
      "35 Cactus fruit\n",
      "True Class - ./fruits-360/train/Lemon Meyer\n",
      "35 Cactus fruit\n",
      "True Class - ./fruits-360/train/Lemon\n",
      "47 Kiwi\n",
      "True Class - ./fruits-360/train/Cactus fruit\n",
      "47 Kiwi\n",
      "True Class - ./fruits-360/train/Strawberry Wedge\n",
      "35 Cactus fruit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "\n",
    "def get_dic_from_two_lists(keys, values):\n",
    "    return { keys[i] : values[i] for i in range(len(keys)) }\n",
    "\n",
    "def draw_test(name, pred, im, dict_labels):\n",
    "    BLACK = [0,0,0]\n",
    "    expanded_image = cv2.copyMakeBorder(im, 80, 0, 0, 100 ,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    cv2.putText(expanded_image, pred, (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2)\n",
    "    cv2.imshow(name, expanded_image)\n",
    "\n",
    "def getRandomImage(path):\n",
    "    \"\"\"function loads a random images from a random folder in our test path \"\"\"\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "    random_directory = np.random.randint(0,len(folders))\n",
    "    path_class = folders[random_directory]\n",
    "    \n",
    "    file_path = path + path_class\n",
    "    print(\"True Class - \" + str(file_path))\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    return cv2.imread(file_path+\"/\"+image_name)    \n",
    "\n",
    "path = './fruits-360/train/' \n",
    "folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "keys =  list(range(0, 80))\n",
    "fruits_dict = get_dic_from_two_lists(keys,folders)\n",
    "\n",
    "for i in range(0,10):\n",
    "    input_im = getRandomImage(path)\n",
    "    input_original = input_im.copy()\n",
    "    input_original = cv2.resize(input_original, None, fx=2, fy=2, interpolation = cv2.INTER_LINEAR)\n",
    "    \n",
    "    input_im = cv2.resize(input_im, (32, 32), interpolation = cv2.INTER_LINEAR)\n",
    "    input_im = input_im / 255.0\n",
    "    input_im = input_im.reshape(1,32,32,3) \n",
    "    \n",
    "    # Get Prediction\n",
    "    #res = np.argmax(classifier.predict(input_im, 1, verbose = 0), axis=1)\n",
    "    res = str(classifier.predict_classes(input_im, 1, verbose = 0)[0])\n",
    "    \n",
    "    fruit = fruits_dict[int(res)]\n",
    "    print(res, fruit)\n",
    "    # Show image with predicted class\n",
    "    draw_test(\"Prediction\", fruit, input_original, fruits_dict) \n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Pear Monster',\n",
       " 1: 'Kumquats',\n",
       " 2: 'Pepino',\n",
       " 3: 'Raspberry',\n",
       " 4: 'Peach',\n",
       " 5: 'Pineapple',\n",
       " 6: 'Apple Red Yellow',\n",
       " 7: 'Mulberry',\n",
       " 8: 'Grape White',\n",
       " 9: 'Clementine',\n",
       " 10: 'Plum',\n",
       " 11: 'Mandarine',\n",
       " 12: 'Physalis',\n",
       " 13: 'Tamarillo',\n",
       " 14: 'Salak',\n",
       " 15: 'Apricot',\n",
       " 16: 'Apple Golden 2',\n",
       " 17: 'Pear',\n",
       " 18: 'Apple Red 3',\n",
       " 19: 'Guava',\n",
       " 20: 'Grapefruit White',\n",
       " 21: 'Mango',\n",
       " 22: 'Tomato 1',\n",
       " 23: 'Apple Red 1',\n",
       " 24: 'Apple Red 2',\n",
       " 25: 'Orange',\n",
       " 26: 'Cantaloupe 2',\n",
       " 27: 'Passion Fruit',\n",
       " 28: 'Banana Red',\n",
       " 29: 'Limes',\n",
       " 30: 'Peach Flat',\n",
       " 31: 'Apple Golden 1',\n",
       " 32: 'Grapefruit Pink',\n",
       " 33: 'Cherry Rainier',\n",
       " 34: 'Lemon Meyer',\n",
       " 35: 'Cactus fruit',\n",
       " 36: 'Physalis with Husk',\n",
       " 37: 'Avocado',\n",
       " 38: 'Cocos',\n",
       " 39: 'Apple Golden 3',\n",
       " 40: 'Grape White 2',\n",
       " 41: 'Pomegranate',\n",
       " 42: 'Apple Granny Smith',\n",
       " 43: 'Walnut',\n",
       " 44: 'Avocado ripe',\n",
       " 45: 'Rambutan',\n",
       " 46: 'Strawberry',\n",
       " 47: 'Kiwi',\n",
       " 48: 'Cantaloupe 1',\n",
       " 49: 'Dates',\n",
       " 50: 'Cherry 1',\n",
       " 51: 'Maracuja',\n",
       " 52: 'Tomato Cherry Red',\n",
       " 53: 'Kaki',\n",
       " 54: 'Lychee',\n",
       " 55: 'Strawberry Wedge',\n",
       " 56: 'Tomato 2',\n",
       " 57: 'Pear Abate',\n",
       " 58: 'Cherry Wax Red',\n",
       " 59: 'Nectarine',\n",
       " 60: 'Quince',\n",
       " 61: 'Cherry Wax Yellow',\n",
       " 62: 'Pear Williams',\n",
       " 63: 'Apple Red Delicious',\n",
       " 64: 'Grape Pink',\n",
       " 65: 'Granadilla',\n",
       " 66: 'Pineapple Mini',\n",
       " 67: 'Papaya',\n",
       " 68: 'Tomato Maroon',\n",
       " 69: 'Carambula',\n",
       " 70: 'Tomato 3',\n",
       " 71: 'Cherry 2',\n",
       " 72: 'Tangelo',\n",
       " 73: 'Apple Braeburn',\n",
       " 74: 'Lemon',\n",
       " 75: 'Cherry Wax Black',\n",
       " 76: 'Huckleberry',\n",
       " 77: 'Tomato 4',\n",
       " 78: 'Pitahaya Red',\n",
       " 79: 'Melon Piel de Sapo'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruits_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
